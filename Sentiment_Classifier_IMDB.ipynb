{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Hlp2bY6GyJUbxHuejIRdCKsPXphCOyFW",
      "authorship_tag": "ABX9TyP8yF0Y90QtLA01NHe/6nAO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marie000/Sentiment_Classifier/blob/main/Sentiment_Classifier_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkZd0caA7IrI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pandas as pd\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "8LpcKSxWCFyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "P7Q-Sq227Pxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"drive/MyDrive/pytorch datasets/IMDB-Dataset.csv\")"
      ],
      "metadata": {
        "id": "fpqRAF4h_aNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9FcDyEzT_rdY",
        "outputId": "60e3093b-10a6-4754-e317-3c4be9c1127d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a27022c2-eb09-4ca1-a470-732be1719353\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a27022c2-eb09-4ca1-a470-732be1719353')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a27022c2-eb09-4ca1-a470-732be1719353 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a27022c2-eb09-4ca1-a470-732be1719353');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4dfa3b2d-41ce-4a4b-a871-34a3544cbf9e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dfa3b2d-41ce-4a4b-a871-34a3544cbf9e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4dfa3b2d-41ce-4a4b-a871-34a3544cbf9e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"sentiment\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIrmxJ8l_yqL",
        "outputId": "d0fdd3a4-9233-4265-831c-41e8907c9161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    25000\n",
              "negative    25000\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test_val, y_train, y_test_val = train_test_split(df[\"review\"], df[\"sentiment\"], test_size=0.2)"
      ],
      "metadata": {
        "id": "-peJ5xIl_2nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train), len(X_test_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFIKqH_Pyihb",
        "outputId": "173be2cf-0f2f-47aa-a26d-1ebbb07fa07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)"
      ],
      "metadata": {
        "id": "Dp9hxIgGCKtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train), len(X_test), len(X_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqQ_KfBTCgrw",
        "outputId": "11149d3d-710f-4f79-d1a2-aeeb7269125e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40000 5000 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data_iter):\n",
        "  for text in data_iter:\n",
        "    yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(X_train), specials=[\"<unk>\", \"<pad>\"], max_tokens=20000)"
      ],
      "metadata": {
        "id": "P6zS2bw7COvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBBJYp6sE4V1",
        "outputId": "5f6fb512-1163-41d3-b640-697072130f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "il1RzIjcURE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))"
      ],
      "metadata": {
        "id": "z4QBRwrLVNyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_pipeline(\"This movie is terrible!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl6SAyAhVVVf",
        "outputId": "a8b60efc-31c8-4ab8-9275-ecfdbf5e5792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14, 20, 10, 384, 36]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = X_train.apply(text_pipeline)\n",
        "# X_val = X_val.apply(text_pipeline)\n",
        "# X_test = X_test.apply(text_pipeline)"
      ],
      "metadata": {
        "id": "0HVJdcdTwupf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_values = ['negative', 'positive']\n",
        "label_pipeline = lambda x: label_values.index(x)"
      ],
      "metadata": {
        "id": "DLJn9mziIDPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train = y_train.apply(label_pipeline)\n",
        "# y_val = y_val.apply(label_pipeline)\n",
        "# y_test = y_test.apply(label_pipeline)"
      ],
      "metadata": {
        "id": "xTSsjnpsIcyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = list(zip(X_train, y_train))\n",
        "val_data = list(zip(X_val, y_val))\n",
        "test_data = list(zip(X_test, y_test))"
      ],
      "metadata": {
        "id": "Fpa0sO_ZGG8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppynwRi-Rh-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbmnkTT8GWh-",
        "outputId": "93575ebc-eccc-4cc0-f0bd-97fb2ba9feb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Director Kinka Usher stays true to his own credo, \"Play it straight and they will laugh,\" and with the help of a superb cast has crafted what should become the #1 cult film of all time, `Mystery Men.\\' When an evil villain, Casanova Frankenstein (Geoffrey Rush) is released from a mental institution, captures the local superhero, Captain Amazing (Greg Kinnear), and threatens to take over Champion City, three wanna-be superheroes, Mr. Furious (Ben Stiller), The Shoveler (William H. Macy) and The Blue Raja (Hank Azaria) come to the rescue. Frankenstein has been joined by a myriad assortment of underworld scum, however, and has become a formidable opponent. The trio realize that help is needed, and decide to recruit; what they end up with is nothing less than the most unforgettable team of `superheroes\\' ever assembled in the history of the cinema. Mr. Furious has his rage; The Shoveler, his shovel; The Blue Raja flings silverware (mainly forks, and the occasional spoon, but never a knife); the Invisible Boy (Kel Mitchell) can turn invisible as long as no one is watching; the Sphinx (Wes Studi), a heavy hitter from down south, is very mysterious and can break guns in half with his mind. Maybe; the Bowler (Janeane Garofalo) can fling a ball with deadly accuracy; and The Spleen (Paul Reubens) wields flatulence that can incapacitate an entire room. This is a brilliant ensemble piece that delivers the laughs without ever becoming condescending or patronizing the audience, while playing it straight at all times. The dialogue is witty, and the performances given by Stiller, Macy, Azaria and Garofalo are exemplary. There is a number of memorable, hilarious scenes, especially the one in which they throw a pool party and barbecue to recruit, and conduct interviews with a stupefying assemblage of applicants; and another, in a bar, when the Bowler has a conversation with her long-dead father, whose skull has been implanted in her bowling ball. The funniest of all, however, has to be when the team actually attempts to rescue Captain Amazing. But these are only examples, for the entire movie is composed of one hilarious scene after another, laced with subtle humor that will keep you laughing and thinking about it for a long time. The real secret of it\\'s success, though, is that Usher keeps it all real; the relationships between the characters are true, and the whole concept of being a `Superhero\\' is played as being entirely reasonable, which somehow gives a sense of credibility to the entire proceedings. In this world, the aspirations of Mr. Furious and the rest are tenable, and Usher keeps the laughs coming without ever resorting to slapstick or mere sight gags. The solid supporting cast includes Lena Olin (Dr. Annabel Leek), Eddie Izzard (Tony P.), Tom Waits (Doc Heller), Claire Forlani (Monica), Louise Lasser (The Blue Raja\\'s mother), Jenifer Lewis (Lucille) and Pras (Tony C.). `Mystery Men\\' is a truly inspired movie that can be seen over and over again, with a new chuckle to be had with every viewing, guaranteed. In the immortal words of the Sphinx, `We are number one! All others are number two, or lower.\\' Is it an Oscar-worthy movie? Hardly; but for a good time and a lot of laughs, treat yourself to this masterwork of comedy; it\\'s the real deal, and you won\\'t regret it. I rate this one 10/10.',\n",
              " 'positive')"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Datasets and DataLoaders\n",
        "\n",
        "I will create the train, test and val datasets as separate datasets instead of subsets of a dataset. I am doing that because it made it easier to create the vocabulary from just the training data."
      ],
      "metadata": {
        "id": "EIM670bOunOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class SentimentDataset(Dataset):\n",
        "\n",
        "#   def __init__(self, X, y):\n",
        "#     self.dataset = torch.tensor(X['x'])\n",
        "#     self.labels = torch.tensor(y.reshape(-1)).long()\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.dataset)\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#     return self.dataset[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "pVQb3y_QVZYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = SentimentDataset(X_train, y_train)\n",
        "# test_data = SentimentDataset(X_test, y_test)\n",
        "# val_data = SentimentDataset(X_val, y_val)"
      ],
      "metadata": {
        "id": "O4WFoBcQEVKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padding_index = vocab[\"<pad>\"]\n",
        "print(padding_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_2AMof_tPKv",
        "outputId": "75bf1673-84b4-4675-9eca-53710d1d592c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_with_padding(data):\n",
        "  text_list, label_list = [], []\n",
        "  for text, label in data:\n",
        "    label_list.append(label_pipeline(label))\n",
        "    text = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
        "    text_list.append(text)\n",
        "  #text_list = torch.cat(text_list).to(device)\n",
        "  text_list = pad_sequence(text_list, batch_first=True, padding_value=padding_index)\n",
        "  label_list = torch.tensor(label_list, dtype=torch.int64, device=device)\n",
        "\n",
        "  return text_list, label_list\n",
        "#   x, y = zip(*data)\n",
        "#   #x = torch.tensor(text_pipeline(x), dtype=torch.int64, device=device)\n",
        "#   x = [text_pipeline(i) for i in x]\n",
        "#   x = torch.tensor(x, dtype=torch.int64, device=device)\n",
        "\n",
        "#   y = [torch.tensor(label_pipeline(i), device=device) for i in y]\n",
        "#   x = pad_sequence(x, batch_first=True, padding_value=padding_index)\n",
        "\n",
        "# # x = torch.tensor(x)\n",
        "#  # y = torch.cat(y)\n",
        "#   y = torch.tensor(y, dtype=torch.int64, device=device)\n",
        "#   #y = torch.stack(y)\n",
        "#   return x, y"
      ],
      "metadata": {
        "id": "8sEBiqOiYHva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    collate_fn = collate_with_padding,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    drop_last = True\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    collate_fn = collate_with_padding,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    drop_last = True\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_data,\n",
        "    collate_fn = collate_with_padding,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    drop_last = True\n",
        ")"
      ],
      "metadata": {
        "id": "9cu4uHwEWToB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "-9r3PT8OpRJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim,num_layers=2, output_dim=2):\n",
        "    super().__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_layers = num_layers\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim,num_layers=num_layers, dropout=0.2)\n",
        "    self.fc = nn.Linear(hidden_dim*num_layers, output_dim)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    self.embedding.weight.data.uniform_(-0.5, 0.5)\n",
        "    #self.rnn.weight.data.uniform_(-0.5, 0.5)\n",
        "    self.fc.weight.data.uniform_(-0.5, 0.5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.permute(1,0)\n",
        "    emb = self.embedding(x)\n",
        "    # output will not be used because we have a many-to-one rnn\n",
        "    output, (hidden, cell) = self.rnn(emb)\n",
        "    hidden.squeeze_(0)\n",
        "    hidden = hidden.transpose(0,1)\n",
        "    hidden = hidden.reshape(-1, self.hidden_dim*self.num_layers)\n",
        "    out = self.fc(hidden)\n",
        "    return out"
      ],
      "metadata": {
        "id": "BRHtr5VNM1Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_SIZE = 64\n",
        "HIDDEN_DIM = 32\n",
        "NUM_LAYERS=2\n",
        "\n",
        "model = RNNModel(vocab_size, EMBED_SIZE, HIDDEN_DIM, num_layers=NUM_LAYERS)"
      ],
      "metadata": {
        "id": "InQT7fBoNj-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc_fn(y_pred, y_true):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct / len(y_pred)) * 100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "cSwx99lZOiZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_values = []\n",
        "train_acc_values = []\n",
        "test_loss_values = []\n",
        "test_acc_values = []"
      ],
      "metadata": {
        "id": "5fHfuYUOPAww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  model.to(device)\n",
        "  train_acc, train_loss = 0, 0\n",
        "  for text, label in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    label, text = label.to(device), text.to(device)\n",
        "    y_pred = model(text)\n",
        "    #logits = logits.float()\n",
        "    #y_pred = logits.argmax(dim=1).float()\n",
        "    #y_pred.requires_grad_(True)\n",
        "    loss = loss_fn(y_pred, label.squeeze())\n",
        "    #loss.requires_grad_(True)\n",
        "    train_loss += loss\n",
        "    train_acc += acc_fn(y_pred.argmax(dim=1), label)\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "  train_loss_values.append(train_loss)\n",
        "  train_acc_values.append(train_acc)\n",
        "  print(f'Train Loss: {train_loss}, Accuracy: {train_acc}')"
      ],
      "metadata": {
        "id": "F6EElOEqPGiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, dataloader, loss_fn):\n",
        "  model.eval()\n",
        "\n",
        "  eval_acc, eval_loss = 0,0\n",
        "  with torch.inference_mode():\n",
        "    for text, label in dataloader:\n",
        "      label, text = label.to(device), text.to(device)\n",
        "      y_pred = model(text)\n",
        "      loss = loss_fn(y_pred, label.squeeze())\n",
        "      eval_loss += loss\n",
        "      eval_acc += acc_fn(y_pred.argmax(dim=1), label)\n",
        "\n",
        "    eval_loss /= len(dataloader)\n",
        "    eval_acc /= len(dataloader)\n",
        "    test_loss_values.append(eval_loss)\n",
        "    test_acc_values.append(eval_acc)\n",
        "    print(f'Test Loss: {eval_loss}, Accuracy: {eval_acc}')"
      ],
      "metadata": {
        "id": "-ufT3Wc0PO2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "zFso5Bd6PY-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f'Epoch: {epoch}\\n------------------')\n",
        "  train(model, train_dataloader, loss_fn, optimizer)\n",
        "  eval(model, val_dataloader, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rgai_EGRPxUj",
        "outputId": "53207d94-8619-417a-89a5-02ed482cbbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "------------------\n",
            "Train Loss: 0.6953838467597961, Accuracy: 50.345\n",
            "Test Loss: 0.692063570022583, Accuracy: 51.34214743589744\n",
            "Epoch: 1\n",
            "------------------\n",
            "Train Loss: 0.681847095489502, Accuracy: 53.98\n",
            "Test Loss: 0.6259027719497681, Accuracy: 65.98557692307692\n",
            "Epoch: 2\n",
            "------------------\n",
            "Train Loss: 0.5081482529640198, Accuracy: 75.865\n",
            "Test Loss: 0.43813061714172363, Accuracy: 79.84775641025641\n",
            "Epoch: 3\n",
            "------------------\n",
            "Train Loss: 0.3842177391052246, Accuracy: 83.545\n",
            "Test Loss: 0.4170593023300171, Accuracy: 82.17147435897436\n",
            "Epoch: 4\n",
            "------------------\n",
            "Train Loss: 0.3349791467189789, Accuracy: 86.4075\n",
            "Test Loss: 0.4025084972381592, Accuracy: 83.41346153846153\n",
            "Epoch: 5\n",
            "------------------\n",
            "Train Loss: 0.30929380655288696, Accuracy: 87.6425\n",
            "Test Loss: 0.3863655924797058, Accuracy: 84.13461538461539\n",
            "Epoch: 6\n",
            "------------------\n",
            "Train Loss: 0.2924521267414093, Accuracy: 88.4425\n",
            "Test Loss: 0.37646836042404175, Accuracy: 84.23477564102564\n",
            "Epoch: 7\n",
            "------------------\n",
            "Train Loss: 0.28012263774871826, Accuracy: 89.07\n",
            "Test Loss: 0.37433475255966187, Accuracy: 84.83573717948718\n",
            "Epoch: 8\n",
            "------------------\n",
            "Train Loss: 0.2635825276374817, Accuracy: 89.7725\n",
            "Test Loss: 0.36912068724632263, Accuracy: 84.53525641025641\n",
            "Epoch: 9\n",
            "------------------\n",
            "Train Loss: 0.3128366768360138, Accuracy: 87.2775\n",
            "Test Loss: 0.40593233704566956, Accuracy: 83.43349358974359\n",
            "Epoch: 10\n",
            "------------------\n",
            "Train Loss: 0.2637617588043213, Accuracy: 89.9075\n",
            "Test Loss: 0.40901631116867065, Accuracy: 84.51522435897436\n",
            "Epoch: 11\n",
            "------------------\n",
            "Train Loss: 0.23446190357208252, Accuracy: 91.21\n",
            "Test Loss: 0.3902733027935028, Accuracy: 85.0761217948718\n",
            "Epoch: 12\n",
            "------------------\n",
            "Train Loss: 0.23457108438014984, Accuracy: 91.2925\n",
            "Test Loss: 0.3962455689907074, Accuracy: 84.93589743589743\n",
            "Epoch: 13\n",
            "------------------\n",
            "Train Loss: 0.21679410338401794, Accuracy: 92.01\n",
            "Test Loss: 0.40770822763442993, Accuracy: 85.45673076923077\n",
            "Epoch: 14\n",
            "------------------\n",
            "Train Loss: 0.21214982867240906, Accuracy: 92.1425\n",
            "Test Loss: 0.40910112857818604, Accuracy: 85.91746794871794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(model, test_dataloader, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQv8liYdfLZ4",
        "outputId": "dbc8a1cd-5efa-439b-cf71-51677cf613d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.40897777676582336, Accuracy: 85.71714743589743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"drive/MyDrive/pytorch datasets/model_0.pt\")"
      ],
      "metadata": {
        "id": "0HBPs7gxQPol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = RNNModel(vocab_size, EMBED_SIZE, HIDDEN_DIM, num_layers=NUM_LAYERS)\n",
        "loaded_model.load_state_dict(torch.load(\"drive/MyDrive/pytorch datasets/model_0.pt\"))\n",
        "loaded_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wanNquUylOa-",
        "outputId": "88792c08-4ad4-4bb1-b6c1-891b0b7addcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNModel(\n",
              "  (embedding): Embedding(20000, 64)\n",
              "  (rnn): LSTM(64, 32, num_layers=2, dropout=0.2)\n",
              "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "mlEyLhM2ll-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(loaded_model, test_dataloader, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYk5eQQHlUVY",
        "outputId": "9a33f073-5c78-4dc6-c678-4769c04aab6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.40897777676582336, Accuracy: 85.71714743589743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "  with torch.no_grad():\n",
        "    text = torch.tensor(text_pipeline(text), dtype=torch.int64, device=device)\n",
        "    text = torch.unsqueeze(text, 0)\n",
        "    output = loaded_model(text)\n",
        "    return label_values[output.argmax(1).item()]"
      ],
      "metadata": {
        "id": "Lsmv8uyelbaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"this movie is pretty good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k_qGULfumbzj",
        "outputId": "7e146ac5-a1cb-47a1-937a-20c82c80fdd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"Better emotional beats and action than the first film. Less to offer in terms of world building which I preferred in RM pt.1. Overall I thought RM pt. 2 was about average but it does have something to say about war, the scars it causes & whether people can heal from that. Both parts work better when watched together. \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Bo0o6wgVmd21",
        "outputId": "82fcc2aa-44d5-49bd-b807-d6a12e2e1058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\" fell asleep the first hour of it. The rest was just so so bad. Why doesn't anyone just tell Zach No. Someone please make it stop. Unwatchable garbage. Some of the stunts were ok but nothing would ever make me sit through it again. I know there are people who love Z snyders work but I am no longer one of them. I love the 300, BvS, watchmen..but this nah. \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BMOv4X0eaCp5",
        "outputId": "40ece3ee-0578-4271-859a-3ab5ff53081c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_example = test_data[128]\n",
        "print(test_example[0])\n",
        "print(test_example[1])\n",
        "predict(test_example[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "obWZGSvgaL0q",
        "outputId": "15691647-6bb6-4cf3-d673-caa5c019b6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I see this movie as a poor tribute to the old slasher movies. Because it really doesn't hold a candle to the 70's and 80's gold-era of horror, this is of course where personal taste comes in.<br /><br />This movie just falls into the category of \"New generation of slashers\" in my book, the cast is the typical ones 18-24 years and potential models. I'm personally quite tired of that image in horror movies, the old movies at least had some variation in people. One or more fat people, and dorks in general. Just plain looking persons, of course having a couple of good lookers is fine they always been there. But when the entire cast is just a bunch of nice racks and butts it's getting silly. I mean, OK yeah i like to watch HOT chicks. But not in a horror that is supposed to reflect some ordinary people getting hunted down by for example a knife-wielding maniac... You expect the people being hunted to look something like any random person you see on the street. I think. There are of course a few movies with just good lookers that is perfectly alright, but they aren't many. \"Wrong turn\" is one example of the better ones.<br /><br />Next point is the killing scenes that slashers should be all about. In this poor movie, all you get to see is 2-3 frames of sudden high pitched sound/scream and music in crescendo. And that's it. The little you do get to see isn't very graphical at all, not for people who have seen some horrors during the years. The old-school slashers compared to this had much more and better death, blood and gore. Not to mention the killers in those movies, who surpassed the one you'll get to see here.<br /><br />As for true horror fans it is more fun and exciting to watch horrors with new approaches because of the originalities that pops up, the killer in this one doesn't add anything new and fresh to the genre in my opinion. I have to agree with what someone previously stated as well, the CGI is something i hate to watch. Personally i preffere the makeups in that sense I'm conservative, (unless the CGI is really well done). But most importantly is to set a good setting of mood which allows you to \"get into the movie\", a good background story is one very good thing. Also revealing and explaining too much of everything in a movie to the viewers takes away all sense of mystic that adds very much of the mood, and doesn't give you much to think about. Just as an example: keeping the killers background a complete mystery for the viewer is a good move in many cases. I mean if everything about the story or the people in it has to be explained or shown in detail, then it's not much content left over for the viewer at all to ponder about... That's like watching a porno movie and hope for a great story in the meantime.<br /><br />Why the old-school slashers still works, at least for some people. Is because they are established cult movies from the era when they were a new thing, making new ones of that sort today is admittedly hard. The exception might be for people who are newer to that sort of horrors of course. I have noticed that many people does like this sort of horror movies, so there are of course not \"A right taste\" for horror movies.<br /><br />But for people out there that might share my opinion; here you have a frame of reference what to expect of this flick.\n",
            "negative\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJfkZBX5jvqe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}